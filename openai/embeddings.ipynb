{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2019-2023 vdaas.org vald team <vald@vdaas.org>\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# You may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#\thttps://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's use the OpenAI Embeddings API and the vector search engine Vald to search for similar sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e332cd-0734-4fda-b43c-333087ebfeed",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "We will use the [AG News](https://huggingface.co/datasets/ag_news) test data this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b5a8f-aa4e-4d6e-8784-39d2cf8537ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets pandas ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3382948c-f66b-4afb-a293-6c36c4565e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ag_news\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8effd10-6a98-4b1a-be16-048e5723865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c33aa-1fb3-4102-b77f-cd69d5e28269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dataset[\"text\"], columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e4892-ce69-41f3-b081-e10788ee44cf",
   "metadata": {},
   "source": [
    "## Vectorization of text\n",
    "There are several ways to vectorize sentences, using the paid OpenAI Embeddings API and the free sentence-transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa25b19a-3033-44e8-8950-1fc0fdef3d24",
   "metadata": {},
   "source": [
    "### When using the OpenAI Embeddings API\n",
    "Please create an OpenAI account and issue your api-key [here](https://platform.openai.com/api-keys) and rewrite sk-XXX on the right side of the following line. Do not put double quotes before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725c68a-5fbf-4f25-bf72-e48fa8daa644",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=sk-XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4080b8-22db-4ba5-9e13-fa8a9b05ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f06fd02-f641-454a-ae28-e35d6da3e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = openai.OpenAI()\n",
    "\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    time.sleep(0.2)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eff1cc-e03d-4ca3-b530-7b1f5f158e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"text-embedding-ada-002\"\n",
    "len(get_embedding(\"This is a test text.\", model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23a418-88cf-4770-8a9e-3fde0f8d2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"text_embedding\"] = df[\"text\"].progress_apply(lambda x: get_embedding(x, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3405fad1-5afc-4c08-90ab-7d1d1fe3301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embedding is processed and saved so that it can be restored.\n",
    "w_df = df.copy()\n",
    "w_df[\"text_embedding\"] = w_df[\"text_embedding\"].apply(list)\n",
    "w_df.to_csv(\"./text-embedding-openai.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe6505-5dab-4c8b-88ce-5ea7e9c5a475",
   "metadata": {},
   "source": [
    "### When using sentence-transformers\n",
    "This example uses a multilingual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff2341-e191-470f-8137-24f7d7c21472",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c472972-e6a6-4b34-bf44-5111b353c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# When using CPU\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "# When using GPU\n",
    "# model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e1963-dcf1-4061-a10a-10e85d24da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model):\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaad15a-af86-4c82-8730-e936f706178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(get_embedding(\"This is a test text.\", model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d010b-a43e-46b3-afd6-8e55eef3b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"text_embedding\"] = df[\"text\"].progress_apply(lambda x: get_embedding(x, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7223dda1-f8fb-4340-b9da-882009b82d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The embedding is processed and saved so that it can be restored.\n",
    "w_df = df.copy()\n",
    "w_df[\"text_embedding\"] = w_df[\"text_embedding\"].progress_apply(list)\n",
    "w_df.to_csv(\"./text-embedding-st.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835f555-1bce-4c8d-9acd-690957e5e639",
   "metadata": {},
   "source": [
    "## Preparation of the Vald cluster\n",
    "Please refer to [Get Started](https://vald.vdaas.org/docs/tutorial/get-started/) here to build a Vald cluster.\n",
    "\n",
    "Set agent.ngt.dimension in values.yaml to the number of dimensions of the vectors you actually want to insert (1536 if you use OpenAI Embeddings API, 768 if you use sentence-transformers). And set agent.ngt.distance_type to l2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b48b6e-3db4-402c-9899-caeddb6b6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vald-client-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1df4b-4ec6-4611-b25a-bb26df3a8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./text-embedding-openai.csv\")\n",
    "# df = pd.read_csv(\"./text-embedding-st.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ae632-1d08-4224-9a06-42384832f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"text_embedding\"] = (\n",
    "    df[\"text_embedding\"].progress_apply(eval).progress_apply(np.array)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169edd5-6a7e-4b05-aa6f-2bfcac68a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import numpy as np\n",
    "from vald.v1.payload import payload_pb2\n",
    "from vald.v1.vald import search_pb2_grpc, upsert_pb2_grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf8275-a4e9-4275-a0e4-6ee867fca674",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Host name to connect to (Host:Port)\n",
    "host = \"localhost:80\"\n",
    "\n",
    "dimension = 1536  # When using OpenAI Embeddings API\n",
    "# dimension = 768  # When using sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ed235-7635-402e-823f-c254ae904bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = grpc.insecure_channel(host)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14c715-1762-48f0-a333-5b6aa3805465",
   "metadata": {},
   "source": [
    "We will try to see if I can insert a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac788a-22fd-4a20-af09-3cf63076c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "usstub = upsert_pb2_grpc.UpsertStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b94152-268e-46d4-be9b-c4e3a7ce672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = payload_pb2.Object.Vector(id=\"0\", vector=df[\"text_embedding\"][0])\n",
    "uscfg = payload_pb2.Upsert.Config(skip_strict_exist_check=True)\n",
    "usstub.Upsert(payload_pb2.Upsert.Request(vector=vec, config=uscfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71b513f-54f3-4c5c-aa33-aef76a6815cf",
   "metadata": {},
   "source": [
    "Try to see if the inserted vectors can be searched. \n",
    "\n",
    "After inserting the data, wait a few minutes because the search results will not be reflected until the index creation is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad7082-7495-4f95-9980-c27f8ed530db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sstub = search_pb2_grpc.SearchStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64b241-daa0-4b20-a0d7-bc3840bd145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svec = np.array([0.01] * dimension, dtype=\"float32\")  # Test vector for query\n",
    "scfg = payload_pb2.Search.Config(num=10, radius=-1.0, epsilon=0.01, timeout=3000000000)\n",
    "sstub.Search(payload_pb2.Search.Request(vector=svec, config=scfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238775ed-a57a-4078-9b5b-cf4636a48f86",
   "metadata": {},
   "source": [
    "## Insert all text into Vald\n",
    "Even after the insertion is complete, the search results will not be reflected until the index creation is finished, so please wait a few more minutes before searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dacc217-2e3b-465e-bcf3-24e7082bf270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "    vec = payload_pb2.Object.Vector(id=str(row.Index), vector=row.text_embedding)\n",
    "    uscfg = payload_pb2.Upsert.Config(skip_strict_exist_check=True)\n",
    "    usstub.Upsert(payload_pb2.Upsert.Request(vector=vec, config=uscfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e1b7ec-3e25-4ca2-a9d2-b509954f3068",
   "metadata": {},
   "source": [
    "## Search for text similar to any query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03f929-25d0-4020-8db2-67c5423a7c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_response(text, model, k):\n",
    "    qvec = get_embedding(text, model)\n",
    "    scfg = payload_pb2.Search.Config(\n",
    "        num=k, radius=-1.0, epsilon=0.01, timeout=3000000000\n",
    "    )\n",
    "    return sstub.Search(payload_pb2.Search.Request(vector=qvec, config=scfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f67fb-db59-41b4-aea3-96c5b320adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_top_k(text, model, k):\n",
    "    response = get_search_response(text, model, k=k)\n",
    "    for result in response.results:\n",
    "        rtext = df[\"text\"][int(result.id)]\n",
    "        rdistance = result.distance\n",
    "        print(f\"text: {rtext}, distance: {rdistance}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6170d63-a162-477f-a5dd-115ee10e1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Automatic identification of difficult sentences.\"\n",
    "display_results_top_k(text, model, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495b36e-2615-4f37-a047-31f33115e64c",
   "metadata": {},
   "source": [
    "# When you do not use a vector search engine\n",
    "Vector distance calculation can also be done by application side calculation. However, with Vald, you can perform fast searches even when the amount of data increases.\n",
    "\n",
    "Since Vald is an approximate nearest neighbor search, you may be concerned about its accuracy. Let's compare the accuracy and speed of Vald with the results of an exact calculation using an example using numpy.\n",
    "\n",
    "The trade-off between accuracy and speed can be adjusted with the parameters of Vald, and in this case, agent.ngt.creation_edge_size=20 and agent.ngt.search_edge_size=40 are set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf18f4-93a1-4df6-9305-cbb4d9c000ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_k_with_numpy(text, df, k):\n",
    "    insert_features = np.array([x for x in df[\"text_embedding\"].values])\n",
    "    query_feature = get_embedding(text=text, model=model)\n",
    "    distances = np.linalg.norm(\n",
    "        query_feature - insert_features, axis=1\n",
    "    )  # Equivalent to distance_type=L2\n",
    "    distance_indexes = np.argsort(distances)[:k]\n",
    "\n",
    "    for idx in distance_indexes:\n",
    "        print(f\"text: {df[\"text\"][int(idx)]}, distance: {distances[int(idx)]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6a8520-b032-43ec-9f2c-a403160317e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Automatic identification of difficult sentences.\"\n",
    "display_top_k_with_numpy(text, df, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b25ef9-8c5b-4871-9226-77cd3a508156",
   "metadata": {},
   "source": [
    "## Comparison of search speed\n",
    "Let's compare the speed of using Vald and calculating vector distances on the application side, changing the amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab44cd4d-b575-48af-a9bd-da529f35934c",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b031665-30ba-48fc-ba67-cc5ed18db856",
   "metadata": {},
   "source": [
    "We wanted about 1M of data after unique processing, so we used the following data set of [wikipedia sentences](https://huggingface.co/datasets/wikitext). \n",
    "\n",
    "Since it uses a large amount of memory and takes a long time, we recommend that you first try to make the data smaller by slicing it, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec51501-dd84-4fb1-9e34-51823be83549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2584c-c286-4db6-a1a4-46eba40f7ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=dataset[\"text\"], columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb534f-aa0c-4eac-99f8-e59804a219ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f863e0-df26-4221-8bd8-6d42a95e249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=\"text\", keep=\"first\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b3129-a686-4fe5-a073-f7eae16d59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20574955-174c-4635-bdd9-e5d1a772d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./wikitext-uniq.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8afafbf-7f03-4291-a70e-f814cbc25d99",
   "metadata": {},
   "source": [
    "### Vectorization of text\n",
    "For speed, use sentence-transformers instead of the OpenAI Embeddings API for vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f34531-2406-4c6e-a864-ebbad2849345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./wikitext-uniq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d554593-9978-4cc8-8462-24436918756e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# When using CPU\n",
    "# model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "# When using GPU\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865790c6-c000-469b-a8c4-7e56c303bef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embedding(text, model):\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60241e31-e02e-4396-88a7-7f13a7ca3c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"text_embedding\"] = df[\"text\"].progress_apply(lambda x: get_embedding(x, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda326a1-f12b-46b0-b1fa-120919d3e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The embedding is processed and saved so that it can be restored.\n",
    "w_df = df.copy()\n",
    "w_df[\"text_embedding\"] = w_df[\"text_embedding\"].apply(list)\n",
    "w_df.to_csv(\"./wikitext-uniq-with-text-embedding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd2d494-064f-4cf4-b520-91909cb79c7a",
   "metadata": {},
   "source": [
    "### Query Speed Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c95bb-1378-45f3-99f9-a7e4452662b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./wikitext-uniq-with-text-embedding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb60ad7-829d-4db4-8753-5b4b609148a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "df[\"text_embedding\"] = (\n",
    "    df[\"text_embedding\"].progress_apply(eval).progress_apply(np.array)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516d61a-2c7b-4037-a769-2e98072d3f02",
   "metadata": {},
   "source": [
    "#### When you do not use a vector search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea75798-6d98-4cc3-9dcd-306cc956c9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_insert_features(df):\n",
    "    insert_features = np.array([x for x in df[\"text_embedding\"].values])\n",
    "    return insert_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b829c7f-73af-4359-92d6-21e1b4313f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_indexes_top_k_with_numpy(insert_features, query_feature, k):\n",
    "    distances = np.linalg.norm(\n",
    "        query_feature - insert_features, axis=1\n",
    "    )  # Equivalent to distance_type=L2\n",
    "    distance_indexes = np.argsort(distances)[:k]\n",
    "\n",
    "    return distance_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3c188-a6cd-4fe9-8d55-42bb3ee21e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Where are the idyllic areas?\"\n",
    "query_feature = get_embedding(text=text, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b4697-4ec3-4798-8687-944515db6411",
   "metadata": {},
   "source": [
    "##### 10,000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f070cc-8514-4c13-839a-6526b5631611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "insert_features = get_insert_features(df[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06746294-95ac-41e4-b334-6716a9ca0e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "indexes = get_indexes_top_k_with_numpy(insert_features, query_feature, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0274ffd0-5bc1-4347-9c1b-e5a6202f7300",
   "metadata": {},
   "source": [
    "##### 100,000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a13b60-d5c5-488b-b817-90d536c73fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "insert_features = get_insert_features(df[:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc8a0b-e505-46a7-93be-57209841133c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "indexes = get_indexes_top_k_with_numpy(insert_features, query_feature, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c37a51-13e4-47a7-9718-b2775d4b0612",
   "metadata": {},
   "source": [
    "##### 970,000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb9ebe8-5b81-4a5e-9888-3771bdc97bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "insert_features = get_insert_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25de20-5c13-4319-a08e-c7dbad616127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "indexes = get_indexes_top_k_with_numpy(insert_features, query_feature, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0526c722-223d-4c16-a19d-6bce8b38bb6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### When you use the vector search engine Vald\n",
    "Since the first communication takes time to establish a connection, please take a second measurement that is closer to the actual speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8b831-f636-41c4-9c0d-c01feb0b9e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import grpc\n",
    "from vald.v1.payload import payload_pb2\n",
    "from vald.v1.vald import search_pb2_grpc, upsert_pb2_grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187dbc49-62fe-4eca-8f23-c2086cadeb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Host name to connect to (Host:Port)\n",
    "host = \"localhost:80\"\n",
    "\n",
    "dimension = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe23609-597e-4f28-a39d-802469bdc7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel = grpc.insecure_channel(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568f771c-eaf0-4942-99db-d1efae055296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "usstub = upsert_pb2_grpc.UpsertStub(channel)\n",
    "sstub = search_pb2_grpc.SearchStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dce9df-3a6a-4889-965d-4a02d55c5217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "uscfg = payload_pb2.Upsert.Config(skip_strict_exist_check=True)\n",
    "\n",
    "\n",
    "def multi_upsert(df, chunk_size=200):\n",
    "    for i in tqdm(range(0, len(df), chunk_size)):\n",
    "        requests = [\n",
    "            payload_pb2.Upsert.Request(\n",
    "                vector=payload_pb2.Object.Vector(\n",
    "                    id=str(row.Index), vector=row.text_embedding\n",
    "                ),\n",
    "                config=uscfg,\n",
    "            )\n",
    "            for row in df[i : i + chunk_size].itertuples()\n",
    "        ]\n",
    "        usstub.MultiUpsert(payload_pb2.Upsert.MultiRequest(requests=requests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f1ba6-5650-4627-a72f-c7b127363e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_indexes_top_k(vec, k):\n",
    "    scfg = payload_pb2.Search.Config(\n",
    "        num=k, radius=-1.0, epsilon=0.01, timeout=3000000000\n",
    "    )\n",
    "    response = sstub.Search(payload_pb2.Search.Request(vector=vec, config=scfg))\n",
    "    return [int(result.id) for result in response.results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79e88b-388b-4da0-8333-b619c30ce2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For initial communication\n",
    "text = \"This is a test text.\"\n",
    "query_feature = get_embedding(text=text, model=model)\n",
    "multi_upsert(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57e1e7-a88a-4cd3-aac5-20b12d86839b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes = get_indexes_top_k(query_feature, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78328ef4-9359-44c7-a6e9-db4b08c31a27",
   "metadata": {},
   "source": [
    "##### 10,000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7a860-7874-4d9a-b452-68b3ad8a8c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multi_upsert(df[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b2a67-399d-4bee-be39-0079aa3ca466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"Where are the idyllic areas?\"\n",
    "query_feature = get_embedding(text=text, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f1a51-ec86-489d-a132-823393e57049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "indexes = get_indexes_top_k(query_feature, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e98719-b61d-4c98-b82e-6024570d7d5c",
   "metadata": {},
   "source": [
    "##### 100,000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0bfef7-23fe-4241-9dee-8a4fb459cdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multi_upsert(df[10000:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae813ec-b21b-49b9-a166-9be440884527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "indexes = get_indexes_top_k(query_feature, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486f710-d99b-4182-bcb1-74acf6bcf8b1",
   "metadata": {},
   "source": [
    "##### 970,000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56697ea-9c59-4a22-9c38-1761d51fbc49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multi_upsert(df[100000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109f90c-9fbf-4cfc-bf46-b9ae28acafd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "indexes = get_indexes_top_k(query_feature, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f81471-7936-437a-84f2-d4dece97c626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T07:27:38.306605Z",
     "iopub.status.busy": "2023-11-15T07:27:38.305895Z",
     "iopub.status.idle": "2023-11-15T07:27:38.310795Z",
     "shell.execute_reply": "2023-11-15T07:27:38.309946Z",
     "shell.execute_reply.started": "2023-11-15T07:27:38.306580Z"
    },
    "tags": []
   },
   "source": [
    "The search speed depends on the vector distribution and settings, but in LY Corporation's in-house environment, the 99%ile value of SEARCH is less than 200 ms even when the number of data is more than 10 million."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a598c8-287f-4295-b04c-0cfd0dd942e4",
   "metadata": {},
   "source": [
    "## Acknowledgments\n",
    "The wikitext used for the data set was used without modification under the following license.\n",
    "\n",
    "https://creativecommons.org/licenses/by-sa/4.0/deed.en\n",
    "\n",
    "We would like to thank Wikipedia and the creator of the data set for making the data available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
